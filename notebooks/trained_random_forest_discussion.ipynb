{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trained Random Forest Model\n",
    "\n",
    "## What is this notebook?\n",
    "The point of this notebook is to provide a discussion of what was learned by training a random forest classifier, and to\n",
    "discuss the thought process behind the way it was trained. We will discuss\n",
    "* Pipeline\n",
    "* Hyperparameter Tuning\n",
    "* Final Model\n",
    "* Model metrics\n",
    "* Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the model\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "The model was trained using an `sklearn` pipeline. This pipeline was in charge of both preprocessing the data, as well\n",
    "as creating the model.\n",
    "\n",
    "The pipeline proceeded as follows:\n",
    "1. Apply statistical standardization.\n",
    "    * Zero-mean data is an assumption of PCA.\n",
    "2. Apply PCA.\n",
    "    *  It was found that 8 principal components allowed for us to explain 95% of the data. This was a good step to take\n",
    "    for two reasons:\n",
    "        1. it reduced the dimensionality of the data from $11 \\to 8$.\n",
    "        2. it helps to reduce noise while retaining the true signal.\n",
    "3. Feed the data to the model.\n",
    "\n",
    "This ultimately proved effective."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "During the process of hyperparameter tuning, the following parameters were considered:\n",
    "\n",
    "* `n_estimators`: the number of decision trees in the final random forest model.\n",
    "* `max_depth`: the maximum depth of any decision tree in the forest.\n",
    "* `criterion`: whether to use entropy or Gini impurity.\n",
    "* `class_weight`: whether to weight each class based off the frequency of the training dataset, or by each bootstrap.\n",
    "* `max_features`: the number of features to consider at each split in the tree.\n",
    "\n",
    "#### Gridsearch\n",
    "\n",
    "To appropriately tune these hyperparmeters, I applied a gridsearch in the `training_RFC.py` file. Each of these search\n",
    "spaces was based off some intuition gleaned from when I initially tried to determine the effectiveness of each model on\n",
    "the dataset.\n",
    "\n",
    "The parameters were searched within the following ranges:\n",
    "\n",
    "* `n_estimators` $\\in \\{50, 100, \\dots, 500\\}$.\n",
    "* `max_depth` $\\in \\{64, 67, \\dots, 88\\} \\cup +\\infty$\n",
    "* `criterion` $\\in \\{ \\text{entropy}, \\text{gini} \\}$\n",
    "* `class_weight` $\\in \\{ \\text{balanced_subsample}, \\text{balanced} \\}$\n",
    "* `max_features` $\\in \\{ 2, 3, 4 \\} \\cup \\text{sqrt}$, where `sqrt` allows for the square-root of the number of features\n",
    "remaining at each decision.\n",
    "\n",
    "#### Validation\n",
    "I applied an 80/20 train/validation split for training the model. During the training, we applied 5-fold cross\n",
    "validation to aid with the grid search.\n",
    "\n",
    "\n",
    "#### Training Process\n",
    "I decided to optimize the weighted F1 score with the model. The weighted F1 score is a weighted average of the f1 scores\n",
    "of each class, with more weight given to the classes with fewer examples (support). Seeing as how the dataset is massively class-\n",
    "imbalanced, it made sense to use a metric that gave more emphasis to minority classes. Furthermore, the f1 score\n",
    "provides a nice balance between optimizing the recall and the precision of each class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-95e957797860>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-1-95e957797860>\"\u001B[1;36m, line \u001B[1;32m3\u001B[0m\n\u001B[1;33m    The following\u001B[0m\n\u001B[1;37m        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final Model and Performance\n",
    "\n",
    "#### The best model parameters\n",
    "It was found that the best model had the parameters:\n",
    "\n",
    "* `n_estimators`: 300\n",
    "* `max_depth`: 64\n",
    "* `criterion`: Gini impurity\n",
    "* `class_weight`: weights balanced by each bootstrap, i.e., `balanced_subsample`\n",
    "* `max_features`: 4\n",
    "\n",
    "#### Building the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from models.data_loader import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We learned from `exploring_data.ipynb` that PCA with 8 principal components is optimal.\n",
    "n_components = 8\n",
    "train_prop = 0.8\n",
    "\n",
    "# Random state to allow for this to be deterministic.\n",
    "random_state = np.random.RandomState(42069)\n",
    "\n",
    "# Define the model with the optimal parameters.\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('standardization', StandardScaler()),\n",
    "    ('pca', PCA(n_components=n_components, random_state=random_state)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        random_state=random_state,\n",
    "        n_estimators=300,\n",
    "        max_depth=64,\n",
    "        criterion='gini',\n",
    "        class_weight='balanced_subsample',\n",
    "        max_features=4\n",
    "    ))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "dl = DataLoader('../data/winequality-red.csv', random_state=random_state)\n",
    "\n",
    "# Load the entire dataset (for a final prediction)\n",
    "X, y = dl.get_all_data()\n",
    "\n",
    "# Load the training and testing data.\n",
    "X_train, X_test, y_train, y_test = dl.train_test_split(test_prop=(1.0-train_prop))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluating the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        pred:3  pred:4  pred:5  pred:6  pred:7  pred:8\n",
      "true:3       0       0       2       0       0       0\n",
      "true:4       0       0       9       3       0       0\n",
      "true:5       0       0     102      28       2       0\n",
      "true:6       0       0      21     110       5       0\n",
      "true:7       0       0       1      14      21       1\n",
      "true:8       0       0       0       0       0       1\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.76      0.77      0.76       132\n",
      "           6       0.71      0.81      0.76       136\n",
      "           7       0.75      0.57      0.65        37\n",
      "           8       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.73       320\n",
      "   macro avg       0.45      0.52      0.47       320\n",
      "weighted avg       0.70      0.73      0.71       320\n",
      "\n",
      "Overall OOS model accuracy: 73.125%\n",
      "Model Performance on Entire Dataset: 94.6216%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peyto\\anaconda3\\envs\\scientificProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\peyto\\anaconda3\\envs\\scientificProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\peyto\\anaconda3\\envs\\scientificProject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the model\n",
    "y_hat = model_pipeline.predict(X_test)\n",
    "\n",
    "# Determine the unique labels from the model\n",
    "unique_labels = np.unique(y_train)\n",
    "\n",
    "# Create a confusion matrix\n",
    "confusion_mtrx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_hat, labels=unique_labels),\n",
    "    index=[f'true:{i}' for i in unique_labels],\n",
    "    columns=[f'pred:{i}' for i in unique_labels]\n",
    ")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtrx)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_hat))\n",
    "\n",
    "print(f\"Overall OOS model accuracy: {round(100*sum(y_hat == y_test) / len(y_hat), 4)}%\")\n",
    "\n",
    "print(f\"Model Performance on Entire Dataset: {round(100*sum(model_pipeline.predict(X) == y) / len(y), 4)}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results and Discussion\n",
    "The model appears to work well, with it performing with $\\approx 73\\%$ accuracy on the 320 data points OOS. Upon\n",
    "using the model to predict on the entire dataset, it predicted with $\\approx 94.6\\%$ accuracy (noting that this is also\n",
    "not a good metric to report, but nice to know).\n",
    "\n",
    "The model has a weighted f1 score of $0.71$, with a recall of $0.73$ and a precision of $0.70$.\n",
    "\n",
    "The model appears to primarily score the majority classes well (as would be expected). It appeared to perform worse with\n",
    "classes $3, 4$.\n",
    "\n",
    "The rest of the interpretation's up to you."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}