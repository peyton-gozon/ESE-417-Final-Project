{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Applying an SVM Model to the Data\n",
    "\n",
    "### Goals:\n",
    "1. Use the insights generated from `exploring_data.ipynb`.\n",
    "    * In particular, we need to standardize the data and reduce the data to 8 features.\n",
    "    * Note that this functionality was added to `data_loader.py`.\n",
    "2. Determine how effective the model is with different kernels.\n",
    "\n",
    "### Load the Data, Apply PCA, Perform a Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models.data_loader import DataLoader\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rs = np.random.RandomState(42069)\n",
    "\n",
    "dl = DataLoader(\"../data/winequality-red.csv\")\n",
    "\n",
    "dl.apply_pca_to_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = dl.train_test_split()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building and Applying the SVM\n",
    "* The goal here is to determine how effective the model is with different kernels\n",
    "    * Kernels to explore: linear (will be bad), polynomial, sigmoid, and Gaussian (probably okay).\n",
    "* No hypertuning of parameters are done, purely to explore what seems to be playing well with the data.\n",
    "\n",
    "Note: the dataset is very imbalanced (as shown in `exploring_data.ipynb`; we have to take this into account when\n",
    "working with an SVM. In particular, we use `class_weight='balanced'` to account for this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel\tClass Balance\tAccuracy Score\n",
      "linear\tunit weight\t0.5604166666666667\n",
      "linear\tbalanced\t0.3854166666666667\n",
      "poly\tunit weight\t0.5520833333333334\n",
      "poly\tbalanced\t0.5625\n",
      "rbf\tunit weight\t0.59375\n",
      "rbf\tbalanced\t0.47291666666666665\n",
      "sigmoid\tunit weight\t0.5104166666666666\n",
      "sigmoid\tbalanced\t0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "import itertools  # Allows us to take a set product with another.\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "class_balance = [None, 'balanced']\n",
    "\n",
    "print(\"Kernel\\tClass Balance\\tAccuracy Score\")\n",
    "for kernel, balance in list(itertools.product(kernels, class_balance)):\n",
    "    # Create a model with the appropriate kernel.\n",
    "    svc = SVC(kernel=kernel, class_weight=balance, random_state=rs)\n",
    "\n",
    "    # Fit the model to the training data.\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Determine how well the model performed and report it.\n",
    "    print(f\"{kernel}\\t{balance if balance is not None else 'unit weight'}\\t{svc.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}